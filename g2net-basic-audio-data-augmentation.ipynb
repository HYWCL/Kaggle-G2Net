{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37077,"databundleVersionId":4333111,"sourceType":"competition"}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic spectrogram image classification with Basic Audio Data Augmentation for G2Net.","metadata":{}},{"cell_type":"markdown","source":"Code modified from JUN KODA's [Basic spectrogram image classification](https://www.kaggle.com/code/junkoda/basic-spectrogram-image-classification).\nIn addition, I'll introduce some basic audio data augmentations for G2Net.","metadata":{}},{"cell_type":"code","source":" COLAB = False\n\nif COLAB == True:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    %cd '/content/drive/MyDrive/Colab Notebooks/kaggle/G2Net2022/code'","metadata":{"id":"w5UprQs8ga3c","outputId":"5374b854-2ac0-42d5-9c0c-dede89cdaf8a","execution":{"iopub.status.busy":"2022-11-08T20:11:28.02448Z","iopub.execute_input":"2022-11-08T20:11:28.025059Z","iopub.status.idle":"2022-11-08T20:11:28.055469Z","shell.execute_reply.started":"2022-11-08T20:11:28.024942Z","shell.execute_reply":"2022-11-08T20:11:28.054588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip3 install timm -q","metadata":{"id":"uBZokyT1gYWD","outputId":"aed15e9e-e33e-4780-9434-cf85f12c2229","execution":{"iopub.status.busy":"2022-11-08T20:11:28.059749Z","iopub.execute_input":"2022-11-08T20:11:28.060417Z","iopub.status.idle":"2022-11-08T20:11:41.710767Z","shell.execute_reply.started":"2022-11-08T20:11:28.060383Z","shell.execute_reply":"2022-11-08T20:11:41.709634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nimport h5py\nimport timm\nimport torch\nimport torch.nn as nn\nimport torchaudio\nimport torchvision.transforms as TF\n\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom timm.scheduler import CosineLRScheduler\n\ndevice = torch.device('cuda')\ncriterion = nn.BCEWithLogitsLoss()\n\n# Train metadata\ndi = '../input/g2net-detecting-continuous-gravitational-waves'\ndf = pd.read_csv(di + '/train_labels.csv')\ndf = df[df.target >= 0]  # Remove 3 unknowns (target = -1)","metadata":{"id":"3Xgw6q0ugYWH","execution":{"iopub.status.busy":"2022-11-08T20:11:41.713014Z","iopub.execute_input":"2022-11-08T20:11:41.713342Z","iopub.status.idle":"2022-11-08T20:11:45.370021Z","shell.execute_reply.started":"2022-11-08T20:11:41.71329Z","shell.execute_reply":"2022-11-08T20:11:45.368808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"tbekTVh-gYWI"}},{"cell_type":"code","source":"transforms_time_mask = nn.Sequential(\n                torchaudio.transforms.TimeMasking(time_mask_param=10),\n            )\n\ntransforms_freq_mask = nn.Sequential(\n                torchaudio.transforms.FrequencyMasking(freq_mask_param=10),\n            )\n\nflip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \nfre_shift_rate = 0.0 # probability of applying the vertical shift\n\ntime_mask_num = 0 # number of time masking\nfreq_mask_num = 0 # number of frequency masking","metadata":{"id":"7Z3rNynhq1gr","execution":{"iopub.status.busy":"2022-11-08T20:11:45.371851Z","iopub.execute_input":"2022-11-08T20:11:45.372221Z","iopub.status.idle":"2022-11-08T20:11:45.381266Z","shell.execute_reply.started":"2022-11-08T20:11:45.372182Z","shell.execute_reply":"2022-11-08T20:11:45.380372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    dataset = Dataset(data_type, df)\n\n    img, y = dataset[i]\n      img (np.float32): 2 x 360 x 128\n      y (np.float32): label 0 or 1\n    \"\"\"\n    def __init__(self, data_type, df, tfms=False):\n        self.data_type = data_type\n        self.df = df\n        self.tfms = tfms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, i):\n        \"\"\"\n        i (int): get ith data\n        \"\"\"\n        r = self.df.iloc[i]\n        y = np.float32(r.target)\n        file_id = r.id\n\n        img = np.empty((2, 360, 128), dtype=np.float32)\n\n        filename = '%s/%s/%s.hdf5' % (di, self.data_type, file_id)\n        with h5py.File(filename, 'r') as f:\n            g = f[file_id]\n\n            for ch, s in enumerate(['H1', 'L1']):\n                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n\n                p = a.real**2 + a.imag**2  # power\n                p /= np.mean(p)  # normalize\n                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n                img[ch] = p\n\n        if self.tfms:\n            if np.random.rand() <= flip_rate: # horizontal flip\n                img = np.flip(img, axis=1).copy()\n            if np.random.rand() <= flip_rate: # vertical flip\n                img = np.flip(img, axis=2).copy()\n            if np.random.rand() <= fre_shift_rate: # vertical shift\n                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n            \n            img = torch.from_numpy(img)\n\n            for _ in range(time_mask_num): # tima masking\n                img = transforms_time_mask(img)\n            for _ in range(freq_mask_num): # frequency masking\n                img = transforms_freq_mask(img)\n        \n        else:\n            img = torch.from_numpy(img)\n                \n        return img, y","metadata":{"id":"3kOMMsyagYWN","execution":{"iopub.status.busy":"2022-11-08T20:11:45.383Z","iopub.execute_input":"2022-11-08T20:11:45.383368Z","iopub.status.idle":"2022-11-08T20:11:45.406267Z","shell.execute_reply.started":"2022-11-08T20:11:45.383333Z","shell.execute_reply":"2022-11-08T20:11:45.405352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Audio Data Augmentation for G2Net.","metadata":{}},{"cell_type":"markdown","source":"* horizontal flip\n* vertical flip\n* vertical shift\n* time masking*\n* frequency masking*\n\n*Reference  \nSpecAugment  \nhttps://arxiv.org/abs/1904.08779","metadata":{}},{"cell_type":"markdown","source":"## Horizontal flip and Vertical flip ","metadata":{}},{"cell_type":"code","source":"dataset = Dataset('train', df, tfms=False)\nimg, y = dataset[10]\n\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()\n\n\nflip_rate = 1.0 # probability of applying the horizontal flip and vertical flip \n\ndataset = Dataset('train', df, tfms=True)\nimg, y = dataset[10]\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T20:11:45.40977Z","iopub.execute_input":"2022-11-08T20:11:45.410128Z","iopub.status.idle":"2022-11-08T20:11:46.730541Z","shell.execute_reply.started":"2022-11-08T20:11:45.410101Z","shell.execute_reply":"2022-11-08T20:11:46.729601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vertical shift","metadata":{}},{"cell_type":"code","source":"dataset = Dataset('train', df, tfms=False)\nimg, y = dataset[10]\n\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()\n\n\nflip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \nfre_shift_rate = 1.0 # probability of applying the vertical shift\n\ndataset = Dataset('train', df, tfms=True)\nimg, y = dataset[10]\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()","metadata":{"id":"KKX7AmjTU8qI","outputId":"448f6ad0-bae2-4e83-8028-c86fdd2fa17b","execution":{"iopub.status.busy":"2022-11-08T20:11:46.73204Z","iopub.execute_input":"2022-11-08T20:11:46.732675Z","iopub.status.idle":"2022-11-08T20:11:47.744117Z","shell.execute_reply.started":"2022-11-08T20:11:46.732636Z","shell.execute_reply":"2022-11-08T20:11:47.743194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time masking","metadata":{}},{"cell_type":"code","source":"dataset = Dataset('train', df, tfms=False)\nimg, y = dataset[10]\n\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()\n\n\nflip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \nfre_shift_rate = 0.0 # probability of applying the vertical shift\ntime_mask_num = 3 # number of time masking\n\ndataset = Dataset('train', df, tfms=True)\nimg, y = dataset[10]\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T20:11:47.745795Z","iopub.execute_input":"2022-11-08T20:11:47.746467Z","iopub.status.idle":"2022-11-08T20:11:48.824375Z","shell.execute_reply.started":"2022-11-08T20:11:47.746429Z","shell.execute_reply":"2022-11-08T20:11:48.82335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Frequency masking","metadata":{}},{"cell_type":"code","source":"dataset = Dataset('train', df, tfms=False)\nimg, y = dataset[10]\n\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()\n\n\nflip_rate = 0.0 # probability of applying the horizontal flip and vertical flip \nfre_shift_rate = 0.0 # probability of applying the vertical shift\ntime_mask_num = 0 # number of time masking\nfreq_mask_num = 3 # number of frequency masking\n\ndataset = Dataset('train', df, tfms=True)\nimg, y = dataset[10]\n\nplt.figure(figsize=(8, 3))\nplt.title('Spectrogram')\nplt.xlabel('time')\nplt.ylabel('frequency')\nplt.imshow(img[0, 0:360])\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T20:11:48.826094Z","iopub.execute_input":"2022-11-08T20:11:48.826785Z","iopub.status.idle":"2022-11-08T20:11:50.033249Z","shell.execute_reply.started":"2022-11-08T20:11:48.826741Z","shell.execute_reply":"2022-11-08T20:11:50.03225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"ejqEYZTxgYWP"}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, name, *, pretrained=False):\n        \"\"\"\n        name (str): timm model name, e.g. tf_efficientnet_b2_ns\n        \"\"\"\n        super().__init__()\n\n        # Use timm\n        model = timm.create_model(name, pretrained=pretrained, in_chans=2)\n\n        clsf = model.default_cfg['classifier']\n        n_features = model._modules[clsf].in_features\n        model._modules[clsf] = nn.Identity()\n\n        self.fc = nn.Linear(n_features, 1)\n        self.model = model\n\n    def forward(self, x):\n        x = self.model(x)\n        x = self.fc(x)\n        return x","metadata":{"id":"W3JQE_UbgYWP","execution":{"iopub.status.busy":"2022-11-08T20:11:50.034801Z","iopub.execute_input":"2022-11-08T20:11:50.035187Z","iopub.status.idle":"2022-11-08T20:11:50.042174Z","shell.execute_reply.started":"2022-11-08T20:11:50.035151Z","shell.execute_reply":"2022-11-08T20:11:50.041148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict and evaluate","metadata":{"id":"eO6YqnT0gYWQ"}},{"cell_type":"code","source":"def evaluate(model, loader_val, *, compute_score=True, pbar=None):\n    \"\"\"\n    Predict and compute loss and score\n    \"\"\"\n    tb = time.time()\n    was_training = model.training\n    model.eval()\n\n    loss_sum = 0.0\n    n_sum = 0\n    y_all = []\n    y_pred_all = []\n\n    if pbar is not None:\n        pbar = tqdm(desc='Predict', nrows=78, total=pbar)\n\n    for img, y in loader_val:\n        n = y.size(0)\n        img = img.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n                y_pred = model(img.to(device))\n\n        loss = criterion(y_pred.view(-1), y)\n\n        n_sum += n\n        loss_sum += n * loss.item()\n\n        y_all.append(y.cpu().detach().numpy())\n        y_pred_all.append(y_pred.sigmoid().squeeze().cpu().detach().numpy())\n\n        if pbar is not None:\n            pbar.update(len(img))\n        \n        del loss, y_pred, img, y\n\n    loss_val = loss_sum / n_sum\n\n    y = np.concatenate(y_all)\n    y_pred = np.concatenate(y_pred_all)\n\n    score = roc_auc_score(y, y_pred) if compute_score else None\n\n    ret = {'loss': loss_val,\n           'score': score,\n           'y': y,\n           'y_pred': y_pred,\n           'time': time.time() - tb}\n    \n    model.train(was_training)  # back to train from eval if necessary\n\n    return ret","metadata":{"id":"B-xWfjWYgYWR","execution":{"iopub.status.busy":"2022-11-08T20:11:50.044061Z","iopub.execute_input":"2022-11-08T20:11:50.044761Z","iopub.status.idle":"2022-11-08T20:11:50.056356Z","shell.execute_reply.started":"2022-11-08T20:11:50.044725Z","shell.execute_reply":"2022-11-08T20:11:50.055329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"id":"3arVeLkRgYWS"}},{"cell_type":"code","source":"model_name = 'tf_efficientnet_b6_ns'\nnfold = 5\nkfold = KFold(n_splits=nfold, random_state=42, shuffle=True)\n\nepochs = 25\nbatch_size = 32\nnum_workers = 2\nweight_decay = 1e-6\nmax_grad_norm = 1000\n\nlr_max = 4e-4\nepochs_warmup = 1.0\n\n\n## setting of audio data augmentation \nflip_rate = 0.5 # probability of applying the horizontal flip and vertical flip \nfre_shift_rate = 1.0 # probability of applying the vertical shift\ntime_mask_num = 1 # number of time masking\nfreq_mask_num = 2 # number of frequency masking\n\nfor ifold, (idx_train, idx_test) in enumerate(kfold.split(df)):\n    print('Fold %d/%d' % (ifold, nfold))\n    torch.manual_seed(42 + ifold + 1)\n\n    # Train - val split\n    dataset_train = Dataset('train', df.iloc[idx_train], tfms=True)\n    dataset_val = Dataset('train', df.iloc[idx_test])\n\n    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n                     num_workers=num_workers, pin_memory=True, shuffle=True, drop_last=True)\n    loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size,\n                     num_workers=num_workers, pin_memory=True)\n\n    # Model and optimizer\n    model = Model(model_name, pretrained=True)\n    model.to(device)\n    model.train()\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n\n    # Learning-rate schedule\n    nbatch = len(loader_train)\n    warmup = epochs_warmup * nbatch  # number of warmup steps\n    nsteps = epochs * nbatch        # number of total steps\n\n    scheduler = CosineLRScheduler(optimizer,\n                  warmup_t=warmup, warmup_lr_init=0.0, warmup_prefix=True, # 1 epoch of warmup\n                  t_initial=(nsteps - warmup), lr_min=1e-6)                # 3 epochs of cosine\n    \n    time_val = 0.0\n    lrs = []\n\n    tb = time.time()\n    print('Epoch   loss          score   lr')\n    for iepoch in range(epochs):\n        loss_sum = 0.0\n        n_sum = 0\n\n        # Train\n        for ibatch, (img, y) in enumerate(loader_train):\n            n = y.size(0)\n            img = img.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n\n            y_pred = model(img)\n            loss = criterion(y_pred.view(-1), y)\n\n            loss_train = loss.item()\n            loss_sum += n * loss_train\n            n_sum += n\n\n            loss.backward()\n\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(),\n                                                       max_grad_norm)\n            optimizer.step()\n            \n            scheduler.step(iepoch * nbatch + ibatch + 1)\n            lrs.append(optimizer.param_groups[0]['lr'])            \n\n        # Evaluate\n        val = evaluate(model, loader_val)\n        time_val += val['time']\n        loss_train = loss_sum / n_sum\n        lr_now = optimizer.param_groups[0]['lr']\n        dt = (time.time() - tb) / 60\n        print('Epoch %d %.4f %.4f %.4f  %.2e  %.2f min' %\n              (iepoch + 1, loss_train, val['loss'], val['score'], lr_now, dt))\n\n    dt = time.time() - tb\n    print('Training done %.2f min total, %.2f min val' % (dt / 60, time_val / 60))\n\n    # Save model\n    ofilename = 'model%d.pytorch' % ifold\n    torch.save(model.state_dict(), ofilename)\n    print(ofilename, 'written')\n\n#     break  # 1 fold only","metadata":{"id":"tkWJ1eXpgYWS","outputId":"ed0dd2e0-114f-4dd5-c5a6-2d8511e78359","execution":{"iopub.status.busy":"2022-11-08T20:11:50.058189Z","iopub.execute_input":"2022-11-08T20:11:50.058535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('LR Schedule: Cosine with linear warmup')\nplt.xlabel('steps')\nplt.ylabel('learning rate')\nplt.plot(lrs)\nplt.show()","metadata":{"id":"gXnX0qHogYWT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict and submit","metadata":{"id":"xRXxBCwRgYWU"}},{"cell_type":"code","source":"submit = pd.read_csv(di + '/sample_submission.csv')\nif COLAB == False:\n    # Load model (if necessary)\n    \n    submit['target'] = 0\n    for i in range(5):\n        model = Model(model_name, pretrained=False)\n        filename = f'model{i}.pytorch'\n        model.to(device)\n        model.load_state_dict(torch.load(filename, map_location=device))\n        model.eval()\n\n        # Predict\n        dataset_test = Dataset('test', submit)\n        loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=64,\n                                                num_workers=num_workers, pin_memory=True)\n\n        test = evaluate(model, loader_test, compute_score=False, pbar=len(submit))\n\n        # Write prediction\n        submit['target'] += test['y_pred']/5\nsubmit.to_csv('submission-5folds.csv', index=False)\nprint('target range [%.2f, %.2f]' % (submit['target'].min(), submit['target'].max()))","metadata":{"id":"FMAAA0_pgYWV","trusted":true},"execution_count":null,"outputs":[]}]}